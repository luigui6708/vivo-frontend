'use server';

import { AI_SYSTEM_PROMPT } from '@/lib/ai_context';

export async function consultAI(query: string) {
    // Simple Keyword Matcher logic to simulate RAG (Retrieval Augmented Generation)
    // In a real production system, this would call OpenAI/Anthropic with the System Prompt.

    const lowerQ = query.toLowerCase();
    let response = "";

    if (lowerQ.includes('brix') || lowerQ.includes('ph') || lowerQ.includes('calidad')) {
        response += " **Regla Encontrada en MER (Calidad):**\n- Brix est谩ndar: > 9.0\n- pH est谩ndar: 2.5 - 4.5\n- Tabla Odoo: [mail.message] en mrp.production.";
    }

    if (lowerQ.includes('stock') || lowerQ.includes('caja') || lowerQ.includes('cera') || lowerQ.includes('inventario')) {
        response += " **Regla de Negocio (Log铆stica):**\n- ALERTA CRTICA si stock < 100 unidades.\n- Acci贸n: Detener empaque y solicitar reabastecimiento.";
    }

    if (lowerQ.includes('recepcion') || lowerQ.includes('lote')) {
        response += " **Estructura T茅cnica (Recepci贸n):**\n- Tabla Odoo: [stock.picking]\n- Tipo: 'incoming'\n- Clave principal: 'name' (Folio).";
    }

    if (lowerQ.includes('orden') || lowerQ.includes('maquila') || lowerQ.includes('produccion')) {
        response += " **Workflow de Producci贸n:**\n- Estados: Draft -> Confirmed -> Progress -> To Close -> Done.\n- REGLA: No cerrar sin aprobaci贸n de Calidad.";
    }

    if (!response) {
        response = " **Asistente Maestro:** No tengo una regla espec铆fica para esa consulta en mi *rbol de Prompts* actual. Intenta preguntar sobre 'Brix', 'Stock', 'Recepciones' o 'Producci贸n'.";
    } else {
        response = " **Asistente Maestro:** He consultado el *rbol de Conocimiento* (lib/ai_context.ts) y esto encontr茅:\n\n" + response;
    }

    await new Promise(r => setTimeout(r, 500)); // Simulate thinking
    return response;
}
